---
phase: 19-error-paths-and-regression-tests
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - tests/list_regression_test.rs
  - tests/config_loading_test.rs
  - tests/tool_filter_call_integration_test.rs
autonomous: true
must_haves:
  truths:
    - "List command regression test passes with various server configurations"
    - "Config loading test validates multiple server types and transports"
    - "Tool filtering combined with tool call integration test passes"
  artifacts:
    - path: "tests/list_regression_test.rs"
      provides: "TEST-15 - List command regression (expanded)"
      min_lines: 200
      exports: ["test_list_no_daemon", "test_list_with_daemon", "test_list_multiple_servers"]
    - path: "tests/config_loading_test.rs"
      provides: "TEST-16 - Config loading with various server configurations"
      min_lines: 150
      exports: ["test_config_stdio_server", "test_config_http_server", "test_config_mixed_servers"]
    - path: "tests/tool_filter_call_integration_test.rs"
      provides: "TEST-17 - Tool filtering + call integration"
      min_lines: 150
      exports: ["test_filter_then_call_tool"]
  key_links:
    - from: "tests/config_loading_test.rs"
      to: "tests/fixtures/mock_mcp_server.rs"
      via: "test configuration with mock servers"
    - from: "tests/tool_filter_call_integration_test.rs"
      to: "src/cli/commands/call.rs"
      via: "filtering logic integration"
---

<objective>
Add regression prevention tests covering list command, config loading with various server configurations, and tool filtering combined with tool call integration.

Purpose: Ensure existing functionality continues working and integration scenarios are covered.
Output: Three test files with 3+ passing tests (TEST-15 expanded, TEST-16, TEST-17).
</objective>

<execution_context>
@./.opencode/get-shit-done/workflows/execute-plan.md
@./.opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@tests/list_regression_test.rs
@tests/tool_call_stdio_tests.rs
@tests/fixtures/mock_mcp_server.rs
@tests/helpers.rs

## Reference Patterns

### Existing List Regression Test (tests/list_regression_test.rs):
```rust
#[test]
fn test_list_no_daemon() {
    cleanup_daemon();
    ensure_binary_built();
    
    let output = Command::new("./target/debug/mcp-cli-rs.exe")
        .args(["list", "--no-daemon"])
        .env("RUST_LOG", "")
        .output();
    // Verify output contains expected content
}
```

### Daemon Test Helper Pattern (from daemon_ipc_tests.rs):
```rust
mod fixtures {
    pub mod daemon_test_helper;
}

let config = fixtures::daemon_test_helper::create_test_config().await?;
let daemon = fixtures::daemon_test_helper::spawn_test_daemon(config).await?;
```

### Test Helpers (tests/helpers.rs):
```rust
pub fn temp_config_file(content: &str) -> (TempDir, PathBuf) { ... }
pub fn create_test_environment() -> TestEnvironment { ... }
```

### Config Structure (from existing tests):
```toml
[[servers]]
name = "test-server"
transport = "stdio"
command = "mock-mcp-server"
args = []
```

### Tool Filtering Pattern:
```rust
// From search command or list output filtering
let tools = client.list_tools().await?;
let filtered: Vec<_> = tools.into_iter()
    .filter(|t| t.name.contains(filter))
    .collect();
```
</context>

<tasks>

<task type="auto">
  <name>Task 1: Expand list regression test (TEST-15)</name>
  <files>tests/list_regression_test.rs</files>
  <action>
Expand tests/list_regression_test.rs with comprehensive regression coverage:

1. Keep existing tests and add new ones:
   - test_list_no_daemon (existing) - direct mode without daemon
   - test_list_with_daemon (new) - via daemon with --require-daemon
   - test_list_json_output (new) - verify --json flag works
   - test_list_multiple_servers (new) - config with 2+ servers
   - test_list_empty_config (new) - graceful handling of empty config

2. Add async variants using tokio::test where needed:
   - For daemon mode tests that need async
   - Use TestEnvironment or daemon_test_helper patterns

3. Implement test_list_with_daemon:
   - Start daemon with test config
   - Run list --require-daemon
   - Verify output contains server info
   - Shutdown daemon

4. Implement test_list_json_output:
   - Run list --json --no-daemon
   - Parse output as JSON
   - Verify structure has servers/tools/fields

5. Implement test_list_multiple_servers:
   - Create config with 2+ mock servers
   - Verify list shows all servers
   - Verify no cross-contamination

6. Error handling:
   - Verify graceful handling of missing config
   - Verify graceful handling of invalid config

7. Use existing patterns:
   - cleanup_daemon() helper
   - ensure_binary_built()
   - DaemonHandle for auto-cleanup
  </action>
  <verify>cargo test --test list_regression_test -- --nocapture</verify>
  <done>All list regression tests pass (5+ test cases)</done>
</task>

<task type="auto">
  <name>Task 2: Add config loading test (TEST-16)</name>
  <files>tests/config_loading_test.rs</files>
  <action>
Create tests/config_loading_test.rs with TEST-16:

1. Test various server configuration scenarios:
   - test_config_stdio_server - stdio transport with command/args
   - test_config_http_server - HTTP transport with url
   - test_config_mixed_servers - both stdio and HTTP in same config
   - test_config_env_vars - server with environment variables
   - test_config_complex_args - args with spaces and special chars

2. Use test helpers from tests/helpers.rs:
   - temp_config_file() for creating temp configs
   - TestEnvironment for setup/cleanup

3. Implementation pattern:
   ```rust
   #[tokio::test]
   async fn test_config_stdio_server() -> Result<()> {
       // Create temp config
       let config_content = r#"
[[servers]]
name = "stdio-server"
transport = "stdio"
command = "mock-mcp-server"
"#;
       let (_temp_dir, config_path) = temp_config_file(config_content);
       
       // Test loading with mcp_cli_rs::config
       let config = mcp_cli_rs::config::load_config(&config_path).await?;
       
       // Verify server loaded correctly
       assert_eq!(config.servers.len(), 1);
       assert_eq!(config.servers[0].name, "stdio-server");
       assert!(matches!(config.servers[0].transport, ServerTransport::Stdio { .. }));
       
       Ok(())
   }
   ```

4. For HTTP server:
   - Verify url field parsed correctly
   - Optional: headers field if supported

5. For mixed servers:
   - Config with one stdio, one HTTP
   - Verify both loaded correctly

6. Verify config validation:
   - Valid configs parse without error
   - Invalid configs return helpful errors

7. Reference src/config types for proper assertions
  </action>
  <verify>cargo test --test config_loading_test -- --nocapture</verify>
  <done>All config loading tests pass (4+ test scenarios)</done>
</task>

<task type="auto">
  <name>Task 3: Add tool filter + call integration test (TEST-17)</name>
  <files>tests/tool_filter_call_integration_test.rs</files>
  <action>
Create tests/tool_filter_call_integration_test.rs with TEST-17:

1. Test end-to-end scenario: filter tools by name pattern, then call specific tool

2. Test cases:
   - test_filter_then_call_tool - filter "echo" from list, then call it
   - test_filter_multiple_tools - filter pattern matching multiple tools
   - test_filter_no_match - verify graceful handling when filter matches nothing
   - test_search_and_call - combine search filtering with tool execution

3. Implementation pattern:
   ```rust
   #[tokio::test]
   async fn test_filter_then_call_tool() -> Result<()> {
       // Spawn mock server with multiple tools (echo, add, fail)
       // Create McpClient
       // List tools
       let tools = client.list_tools().await?;
       
       // Filter for "echo" tool
       let filtered: Vec<_> = tools.iter()
           .filter(|t| t.name.contains("echo"))
           .collect();
       assert_eq!(filtered.len(), 1);
       
       // Call the filtered tool
       let result = client.call_tool(&filtered[0].name, json!({"message": "test"})).await?;
       
       // Verify result
       assert!(result.get("content").is_some());
       
       Ok(())
   }
   ```

4. Alternative: Test at CLI level using Command API:
   - mcp-cli-rs search <pattern> to filter
   - mcp-cli-rs call <server> <tool> to execute
   - Verify integration between search and call commands

5. Verify error scenarios:
   - Calling non-existent tool after filtering (shouldn't happen but verify)
   - Filter matching multiple tools - disambiguation

6. Use existing patterns:
   - Mock server spawning from tool_call_stdio_tests.rs
   - TestStdioTransport implementation
   - Proper cleanup

7. If CLI-level test:
   - Use Command::new with --no-daemon for determinism
   - Parse JSON output where applicable
   - Verify both commands exit successfully
  </action>
  <verify>cargo test --test tool_filter_call_integration_test -- --nocapture</verify>
  <done>Tool filtering + call integration test passes</done>
</task>

</tasks>

<verification>
1. All regression tests pass: cargo test --test list_regression_test --test config_loading_test --test tool_filter_call_integration_test
2. Existing list_regression_test.rs functionality preserved and expanded
3. Tests cover:
   - List command with various flags and modes
   - Config loading for all server transport types
   - Tool filtering combined with execution
4. No regressions in existing functionality
</verification>

<success_criteria>
- TEST-15: List regression tests expanded with 5+ test cases covering daemon, JSON, multiple servers
- TEST-16: Config loading tests validate stdio, HTTP, mixed, env vars, complex args
- TEST-17: Tool filtering + call integration test passes end-to-end
- All tests run successfully: cargo test --test list_regression_test --test config_loading_test --test tool_filter_call_integration_test
- No existing tests broken
</success_criteria>

<output>
After completion, create `.planning/phases/19-error-paths-and-regression-tests/19-02-SUMMARY.md`
</output>
