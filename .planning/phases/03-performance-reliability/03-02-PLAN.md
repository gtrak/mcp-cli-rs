---
phase: 03-performance-reliability
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - src/parallel.rs
  - src/lib.rs
autonomous: true
user_setup: []

must_haves:
  truths:
    - "ParallelExecutor can list tools from multiple servers concurrently"
    - "Concurrency is limited by configurable semaphore (default 5)"
    - "Partial failures are tracked and returned separately from successes"
    - "list_tools_parallel returns tuples of (successes, failures) for flexible error handling"
  artifacts:
    - path: "src/parallel.rs"
      provides: "Parallel server discovery infrastructure"
      exports: ["ParallelExecutor", "list_tools_parallel"]
      contains: "use futures::stream"
    - path: "src/lib.rs"
      provides: "Module exports"
      contains: "pub mod parallel"
  key_links:
    - from: "src/parallel.rs"
      to: "src/cli/commands.rs"
      via: "list_tools_parallel function"
      pattern: "list_tools_parallel.*concurrency"
    - from: "src/parallel.rs"
      to: "src/ipc/ProtocolClient"
      via: "daemon.list_tools() calls"
      pattern: "daemon\.list_tools\(\)\.await"
---

<objective>
Create parallel execution infrastructure for concurrent server discovery with configurable concurrency limits.

Purpose: Implement DISC-05 (parallel server discovery with configurable concurrency) and prepare infrastructure for partial failure warnings (ERR-07). Uses futures::stream::buffer_unordered with tokio::sync::Semaphore for controlled concurrency, preventing resource exhaustion while improving performance.

Output: src/parallel.rs module with ParallelExecutor and list_tools_parallel function, integrated with daemon IPC for tool listing.
</objective>

<execution_context>
@.opencode/get-shit-done/workflows/execute-plan.md
@.opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/REQUIREMENTS.md
@.planning/phases/03-performance-reliability/03-RESEARCH.md
@src/cli/commands.rs
@src/ipc/mod.rs
@src/config/mod.rs
</context>

<tasks>

<task type="auto">
  <name>Create parallel execution module with tool discovery</name>
  <files>src/parallel.rs</files>
  <action>Create a new file src/parallel.rs with parallel execution infrastructure:

```rust
//! Parallel execution utilities for MCP operations.
//!
//! Provides concurrent processing of multiple servers with configurable
//! concurrency limits. Implements DISC-05: parallel server discovery.

use futures::stream::{self, StreamExt};
use tokio::sync::Semaphore;
use std::sync::Arc;
use crate::client::ToolInfo;
use crate::error::Result;

/// Parallel executor for MCP operations with concurrency control.
pub struct ParallelExecutor {
    /// Maximum concurrent operations.
    concurrency_limit: usize,
}

impl ParallelExecutor {
    /// Create a new ParallelExecutor with the specified concurrency limit.
    pub fn new(concurrency_limit: usize) -> Self {
        Self {
            concurrency_limit,
        }
    }

    /// Get the concurrency limit.
    pub fn concurrency_limit(&self) -> usize {
        self.concurrency_limit
    }
}

impl Default for ParallelExecutor {
    fn default() -> Self {
        Self::new(5) // DISC-05 default: 5 concurrent operations
    }
}

/// List tools from multiple servers in parallel.
///
/// Processes servers concurrently up to the concurrency limit, tracking
/// successes and failures separately. Implements DISC-05 and prepares ERR-07.
///
/// # Arguments
/// * `server_names` - List of server names to process
/// * `list_fn` - Async function to list tools for a server
///
/// # Returns
/// Tuple of (successes, failures) where:
/// - successes: Vec<(String, Vec<ToolInfo>)> of server name and tools
/// - failures: Vec<String> of server names that failed
///
/// # Example
/// ```rust,ignore
/// let (successes, failures) = list_tools_parallel(
///     server_names,
///     |server| async move { daemon.list_tools(&server).await },
///     executor,
/// ).await?;
/// ```
pub async fn list_tools_parallel<F, Fut>(
    server_names: Vec<String>,
    list_fn: F,
    executor: &ParallelExecutor,
) -> Result<(Vec<(String, Vec<ToolInfo>)>, Vec<String>)>
where
    F: Fn(String) -> Fut + Send + Sync,
    Fut: std::future::Future<Output = Result<Vec<ToolInfo>>> + Send,
{
    // Create semaphore to limit concurrent operations (research: buffer_unordered pattern)
    let semaphore = Arc::new(Semaphore::new(executor.concurrency_limit()));

    // Process each server with concurrency control using stream combinators
    let results = stream::iter(server_names)
        .map(move |server_name| {
            let semaphore = semaphore.clone();
            let list_fn = &list_fn;

            async move {
                // Acquire permit before starting operation (prevents resource exhaustion)
                let _permit = semaphore.acquire().await.unwrap();

                // Execute the list function for this server
                match list_fn(server_name.clone()).await {
                    Ok(tools) => Ok((server_name, tools)),
                    Err(_) => Err(server_name), // Return failed server name
                }
            }
        })
        .buffer_unordered(executor.concurrency_limit()) // Enforce concurrency limit
        .collect::<Vec<Result<(String, Vec<ToolInfo>)>>>()
        .await;

    // Separate successes and failures for error reporting (ERR-07 preparation)
    let mut successes = Vec::new();
    let mut failures = Vec::new();

    for result in results {
        match result {
            Ok(success) => successes.push(success),
            Err(server_name) => failures.push(server_name),
        }
    }

    Ok((successes, failures))
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_parallel_executor_default() {
        let executor = ParallelExecutor::default();
        assert_eq!(executor.concurrency_limit(), 5);
    }

    #[test]
    fn test_parallel_executor_custom_limit() {
        let executor = ParallelExecutor::new(10);
        assert_eq!(executor.concurrency_limit(), 10);
    }
}
```

Key implementation details:
- Uses futures::stream::buffer_unordered for parallel processing with concurrency control (per research)
- Semaphore prevents resource exhaustion by limiting active operations
- Returns tuple of (successes, failures) for flexible error handling (ERR-07)
- Generic list_fn allows use with daemon.list_tools() or direct McpClient.list_tools()
- Tokio async primitives (Semaphore, futures) integrate with existing async architecture</action>
  <verify>Run `cargo check` to verify the parallel module compiles. Ensure that futures-util (already in dependencies) provides StreamExt trait.</verify>
  <done>src/parallel.rs exists with ParallelExecutor and list_tools_parallel, code compiles, tests pass.</done>
</task>

<task type="auto">
  <name>Add parallel module to lib exports</name>
  <files>src/lib.rs</files>
  <action>Add the parallel module to src/lib.rs exports:

Find the module declaration section in lib.rs (after existing modules) and add:
```rust
pub mod parallel;
```

If lib.rs doesn't exist or has a different structure, add the module declaration in the appropriate location that matches the existing pattern (likely after error, config, client modules).

This makes the ParallelExecutor and list_tools_parallel available to CLI commands.</action>
  <verify>Run `cargo check` to verify the module is accessible. Test with `cargo test` if there are integration tests in other modules.</verify>
  <done>parallel module exported in lib.rs, code compiles, ParallelExecutor and list_tools_parallel accessible from other modules.</done>
</task>

</tasks>

<verification>
Run `cargo check` to verify all changes compile together:
- src/parallel.rs with ParallelExecutor and list_tools_parallel
- lib.rs exports parallel module
- futures-util provides StreamExt (buffer_unordered)
- tokio::sync::Semaphore available

Expected: No compilation errors, parallel utilities ready for CLI integration.

Run `cargo test` to verify unit tests in parallel module pass.
</verification>

<success_criteria>
1. src/parallel.rs module exists with ParallelExecutor struct (default concurrency_limit=5)
2. list_tools_parallel function accepts server_names, generic list_fn, and executor, returns (successes, failures)
3. Implementation uses futures::stream::buffer_unordered with Arc<Semaphore> for concurrency control
4. Successes and failures tracked separately (Vec of tuples vs Vec of strings)
5. Module exported in lib.rs
6. Code compiles and tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/03-performance-reliability/03-02-SUMMARY.md`
</output>
